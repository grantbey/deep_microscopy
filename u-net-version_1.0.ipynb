{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net model\n",
    "\n",
    "This notebook contains the code for initializing and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restart_kernel(restart=False):\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    if restart:\n",
    "        app.kernel.do_shutdown(True)\n",
    "\n",
    "restart_kernel(False)\n",
    "\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=cpu,lib.cnmem=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Activation, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, ZeroPadding2D, Cropping2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#import skimage.exposure\n",
    "#import cv2\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pushbullet import Pushbullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concerns:\n",
    "# This won't work for multichannel images\n",
    "# Potentially comment out lines 636-643 in image.py (https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py)\n",
    "# NOTE: MUST shuffle the data in the HDF5 file...\n",
    "\n",
    "# Outline arguments\n",
    "data_gen_args = dict(featurewise_center=False,\n",
    "                     featurewise_std_normalization=False,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2,\n",
    "                     fill_mode='reflect',\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     data_format='channels_last')\n",
    "\n",
    "# Initialize generators\n",
    "img_datagen = ImageDataGenerator(**data_gen_args)\n",
    "msk_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Make data sources\n",
    "filename = 'mosaic_1'\n",
    "with h5py.File('./data/training-data/{}.hdf5'.format(filename),'r+') as f:\n",
    "    x = f['x'][:,:,:,2:3]\n",
    "    y = f['y_nuclei'][...]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "#del x,y\n",
    "\n",
    "# Fit the generators\n",
    "seed=1\n",
    "img_datagen.fit(x_train,augment=True,seed=seed)\n",
    "msk_datagen.fit(y_train,augment=True,seed=seed)\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "img_train_generator = img_datagen.flow(x=x_train,batch_size=batch_size,shuffle=False)\n",
    "msk_train_generator = msk_datagen.flow(x=y_train,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "img_val_generator = img_datagen.flow(x=x_val,batch_size=batch_size,shuffle=False)\n",
    "msk_val_generator = msk_datagen.flow(x=y_val,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "train_generator = zip(img_train_generator, msk_train_generator)\n",
    "val_generator = zip(img_val_generator, msk_val_generator)\n",
    "\n",
    "# Call the flow() method\n",
    "#model.fit_generator(train_generator,\n",
    "#                    steps_per_epoch=196, epochs=100,validation_data='XXX', callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is run # 4\n"
     ]
    }
   ],
   "source": [
    "# Increment the counter\n",
    "def counter():\n",
    "    run = np.load('./data/misc/run_counter.npy')\n",
    "    run += 1\n",
    "    np.save('./data/misc/run_counter.npy',run)\n",
    "    return run\n",
    "run = counter()\n",
    "\n",
    "# Set the counter to a specific value\n",
    "def set_counter(run):\n",
    "    run = run\n",
    "    np.save('./data/misc/run_counter.npy',run)\n",
    "    return run\n",
    "# Uncomment the next line to manually set the counter if something goes wrong\n",
    "#run = set_counter(2)\n",
    "print('This is run # %i' %run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.72 s, sys: 51 ms, total: 3.77 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def compiler(img_rows = x_train.shape[1],img_cols = x_train.shape[2],\n",
    "            nfilters = 64, act = 'relu',init = 'he_normal',\n",
    "            lr=0.001,decay=0.0,rate=[0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2],transpose=False):\n",
    "    \n",
    "    def jaccard(y_true, y_pred,smooth=1.):\n",
    "        intersection = K.sum(y_true * y_pred)\n",
    "        return (intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) - intersection + smooth)\n",
    "    \n",
    "    def Conv2DReluBatchNorm(n_filter, filter_size, layer_in, activation, kernel_initializer='he_uniform'):\n",
    "        return BatchNormalization(axis=1)(Activation(activation=act)((Conv2D(n_filter, filter_size, padding='same',kernel_initializer=init)(layer_in))))\n",
    "        \n",
    "    def up_conv(nfilters,filter_factor,layer_in,kernel_initializer=init,activation=act):\n",
    "        if transpose: # This will perform transposed convolution\n",
    "            return BatchNormalization(axis=1)(Activation(activation=act)(Conv2D(nfilters*filter_factor, (2, 2), padding='same',kernel_initializer=init)(Conv2DTranspose(nfilters*filter_factor,(2,2),strides=2,padding='valid',kernel_initializer=init,activation='relu',data_format='channels_last')(layer_in))))\n",
    "        else: # This is the original upsampling operation\n",
    "            return BatchNormalization(axis=1)(Activation(activation=act)(Conv2D(nfilters*filter_factor, (2, 2), padding='same',kernel_initializer=init)(UpSampling2D(size=(2, 2))(layer_in))))\n",
    "        \n",
    "    inputs = Input((img_rows, img_cols,1))\n",
    "    \n",
    "    conv1 = Conv2DReluBatchNorm(nfilters, (3, 3), inputs, activation=act,kernel_initializer=init)\n",
    "    conv1 = Conv2DReluBatchNorm(nfilters, (3, 3), conv1, activation=act,kernel_initializer=init)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(rate=rate[0])(pool1)\n",
    "\n",
    "    conv2 = Conv2DReluBatchNorm(nfilters*2, (3, 3), pool1, activation=act,kernel_initializer=init)\n",
    "    conv2 = Conv2DReluBatchNorm(nfilters*2, (3, 3), conv2, activation=act,kernel_initializer=init)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(rate=rate[1])(pool2)\n",
    "\n",
    "    conv3 = Conv2DReluBatchNorm(nfilters*4, (3, 3), pool2, activation=act,kernel_initializer=init)\n",
    "    conv3 = Conv2DReluBatchNorm(nfilters*4, (3, 3), conv3, activation=act,kernel_initializer=init)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(rate=rate[2])(pool3)\n",
    "\n",
    "    conv4 = Conv2DReluBatchNorm(nfilters*8, (3, 3), pool3, activation=act,kernel_initializer=init)\n",
    "    conv4 = Conv2DReluBatchNorm(nfilters*8, (3, 3), conv4, activation=act,kernel_initializer=init)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(rate=rate[3])(pool4)\n",
    "\n",
    "    conv5 = Conv2DReluBatchNorm(nfilters*16, (3, 3), pool4, activation=act,kernel_initializer=init)\n",
    "    conv5 = Conv2DReluBatchNorm(nfilters*16, (3, 3), conv5, activation=act,kernel_initializer=init)\n",
    "    conv5 = Dropout(rate=rate[4])(conv5)\n",
    "        \n",
    "    up6 = Concatenate(axis=3)([up_conv(nfilters,8,conv5), conv4])\n",
    "    #up6 = merge([up_conv(nfilters,8,conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Conv2DReluBatchNorm(nfilters*8, (3, 3), up6, activation=act,kernel_initializer=init)\n",
    "    conv6 = Conv2DReluBatchNorm(nfilters*8, (3, 3), conv6, activation=act,kernel_initializer=init)\n",
    "    conv6 = Dropout(rate=rate[5])(conv6)\n",
    "    \n",
    "    up7 = Concatenate(axis=3)([up_conv(nfilters,4,conv6), conv3])\n",
    "    #up7 = merge([up_conv(nfilters,4,conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Conv2DReluBatchNorm(nfilters*4, (3, 3), up7, activation=act,kernel_initializer=init)\n",
    "    conv7 = Conv2DReluBatchNorm(nfilters*4, (3, 3), conv7, activation=act,kernel_initializer=init)\n",
    "    conv7 = Dropout(rate=rate[6])(conv7)\n",
    "    \n",
    "    up8 = Concatenate(axis=3)([up_conv(nfilters,2,conv7), conv2])\n",
    "    #up8 = merge([up_conv(nfilters,2,conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Conv2DReluBatchNorm(nfilters*2, (3, 3), up8, activation=act,kernel_initializer=init)\n",
    "    conv8 = Conv2DReluBatchNorm(nfilters*2, (3, 3), conv8, activation=act,kernel_initializer=init)\n",
    "    conv8 = Dropout(rate=rate[7])(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=3)([up_conv(nfilters,1,conv8), conv1])\n",
    "    #up9 = merge([up_conv(nfilters,1,conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Conv2DReluBatchNorm(nfilters, (3, 3), up9, activation=act,kernel_initializer=init)\n",
    "    conv9 = Conv2DReluBatchNorm(nfilters, (3, 3), conv9, activation=act,kernel_initializer=init)\n",
    "    conv9 = Dropout(rate=rate[8])(conv9)\n",
    "    \n",
    "    conv10 = Conv2DReluBatchNorm(1, (1, 1), conv9, activation=act,kernel_initializer=init)\n",
    "    output = Activation(activation='sigmoid')(conv10)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=lr,decay=decay), loss='binary_crossentropy',metrics=[jaccard])\n",
    "\n",
    "    return model\n",
    "\n",
    "rate=[0]*9\n",
    "#rate=[0.1,0.2,0.3,0.4,0.5,0.4,0.3,0.2,0.1] # current version\n",
    "#rate=[0.2,0.3,0.4,0.5,0.5,0.5,0.4,0.3,0.2] # symmetric but more dropout\n",
    "#rate=[0.2,0.2,0.3,0.3,0.4,0.4,0.5,0.5,0.6] # increasing\n",
    "\n",
    "model = compiler(img_rows=x_train.shape[1],img_cols=x_train.shape[2],\n",
    "            nfilters=16,act='relu',init='he_normal',\n",
    "            lr=0.001,rate=rate,transpose=False)\n",
    "model.save_weights('./data/misc/initial_weights.hdf5')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is run # 4\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 201s - loss: 0.7229 - jaccard: 0.1594 - val_loss: 0.6829 - val_jaccard: 0.1595\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/50\n",
      "14/15 [===========================>..] - ETA: 11s - loss: 0.6867 - jaccard: 0.1600 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "def trainer(model,epochs=1000,fit=True,use_existing=False):\n",
    "    print('This is run # {}'.format(run))\n",
    "    \n",
    "    if use_existing:\n",
    "        model.load_weights('./data/weights/model_weights_nuclei_run_{}.hdf5'.format(run))\n",
    "        \n",
    "    if fit:\n",
    "        quitter = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=50, verbose=1, mode='auto')\n",
    "        lrreducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, verbose=1, mode='auto', epsilon=0.001, cooldown=2, min_lr=0)\n",
    "        model_checkpoint = ModelCheckpoint('./data/weights/model_weights_run_{}_nuclei.hdf5'.format(run), monitor='val_loss', save_best_only=True)\n",
    "        csvlogger = CSVLogger('./data/logs/training_log_run_{}_nuclei.csv'.format(run), separator=',', append=True)\n",
    "        # tensorboard = TensorBoard(log_dir='./data/logs/'+'tensorboard_all-classes-run_{:04d}'.format(run), histogram_freq=0, write_graph=True, write_images=False)\n",
    "        # tensorboard --logdir=data/logs\n",
    "        \n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=15, epochs=50,validation_data=val_generator, validation_steps=5,callbacks=[model_checkpoint,csvlogger])\n",
    "            \n",
    "    preds = model.predict(x, verbose=1)\n",
    "    np.save('./data/predictions/predictions_run_{}_nuclei.npy'.format(run), preds)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = trainer(model,fit=True,use_existing=False)\n",
    "model.save('./data/models/u-net-complete-model-run_{}_nuclei.hdf5'.format(run))\n",
    "push('Training  is done',\n",
    " 'Train loss: %f, train jaccard: %f' %(model.history.history['loss'][-1],model.history.history['jaccard'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
